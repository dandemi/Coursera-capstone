{"cells": [{"metadata": {}, "cell_type": "code", "source": "#Imports\n\nimport numpy as np # library to handle data in a vectorized manner\n\nimport pandas as pd # library for data analsysis\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport json # library to handle JSON files\n\n#!conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab - DONE\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\n#Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\nimport matplotlib.pyplot as plt\n\n#import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab -  DONE\nimport folium # map rendering library\n\nfrom math import sin, cos, sqrt, atan2, radians\n\n\n\nprint('Libraries imported.')", "execution_count": null, "outputs": [{"output_type": "stream", "text": "Solving environment: \\ ", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Introduction\nThe aim of this project is to enhance electric mobility in Barcelona as part of the IBM Capstone on Data Science. It locates the nearest electric parking stations near to a referenced food venue from Foursquare within Barcelona.\nThe project clusters Barcelona\u2019s neighborhood based on the most common type of restaurants venues from Foursquare and to a selected place locates the nearest electric vehicle charging stations. \n"}, {"metadata": {}, "cell_type": "markdown", "source": "\n"}, {"metadata": {}, "cell_type": "code", "source": "### Data readiness \n\nThe initial data requires identifying and locating Barcelona\u2019s neighborhood. The data used in this project has been downloaded from the Barcelona City Hall Open Data website. \nOnce Barcelona\u2019s neighborhoods have been listed, the list of addresses including street coordinates was used to generate the neighborhood coordinates as the mean of each one of its different addresses. Albeit it might not be the official neighborhood\u2019s coordinates; it should be representative as an average among all their addresses.\nThree different databases were loaded; two of them to compile the required information about Barcelona\u2019s neighborhoods and the third include the reference to the electric charging stations in Barcelona which had the coordinates.\n\nData extractet from Barcelona city hall open data. \n\nSource: https://opendata-ajuntament.barcelona.cat/en/\n\n1. Get neighborhoods list and addresses with coordinates.\n2. Merge neighborhoods with coordinates mean", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "### Load file with Barcelona neighborhoods\nimport types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\nclient_634f0334f89f49259087cb8a63af5ecf = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='_BDh8zOunGUBK1B1_gxMeEDwKMmz6SlqEtCePSAMsRZY',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.eu-geo.objectstorage.service.networklayer.com')\n\nbody = client_634f0334f89f49259087cb8a63af5ecf.get_object(Bucket='pythonbasics-donotdelete-pr-m6t3t6sj4zu1mf',Key='2019_superficie.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf_data_1 = pd.read_csv(body)\ndf_bcn = df_data_1[['Codi_Barri','Nom_Barri', 'Nom_Districte']]\ndf_bcn.set_index('Codi_Barri')\n\ndf_bcn.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Extract data from a stored csv file with BCN addresses\nbody = client_634f0334f89f49259087cb8a63af5ecf.get_object(Bucket='pythonbasics-donotdelete-pr-m6t3t6sj4zu1mf',Key='TAULA_DIRELE.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf_data_2 = pd.read_csv(body)\ndf_data_2 = df_data_2.groupby(['BARRI']).mean().reset_index()\n\ndf_coord = df_data_2[['BARRI','LATITUD', 'LONGITUD']]\n#df_coord = df_coord.groupby(['BARRI']).mean()\n\n#df_coord.set_index('BARRI')\ndf_coord.rename(columns={\"BARRI\":\"Codi_Barri\"}, inplace=True)\n\nlist(df_coord)\ndf_coord\n               ", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Merge both dataframes\ndf_bcn = df_bcn.merge(df_coord)\ndf_bcn", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Extract neighborhoods data\ndf_bcn.info()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Shape\ndf_bcn.shape", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Start mapping the data into map\n\nPrint map with neighborhoods"}, {"metadata": {}, "cell_type": "code", "source": "#with open('geocoder_data.json') as json_data:\n#    toronto_data = json.load(json_data)\nurl = 'https://geocoder.readthedocs.io/index.html'\n\n\n!pip install geocoder\nimport geocoder # import geocoder\n\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def get_geocoder(postal_code_from_df):\n    \n    # initialize your variable to None\n    lat_lng_coords = None\n    # loop until you get the coordinates\n    while(lat_lng_coords is None):\n        g = geocoder.google('{}, Barcelona, Spain'.format(postal_code_from_df))\n        lat_lng_coords = g.latlng\n        \n    latitude = lat_lng_coords[0]\n    print(latitude)\n    longitude = lat_lng_coords[1]\n    return latitude, longitude", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Filter by District\n\nCenter in barcelona and plot neighborhoods into a map"}, {"metadata": {}, "cell_type": "code", "source": "#Center map in Barcelona\ngeolocator = Nominatim(user_agent=\"Barcelona\")\nlocation = geolocator.geocode('Barcelona')\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geograpical coordinate of Barcelona are {}, {}.'.format(latitude, longitude))\n\n", "execution_count": null, "outputs": []}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "### create map of Barcelona using latitude and longitude values\nmap_bcn = folium.Map(location=[latitude, longitude], zoom_start=12)\n\n# add markers to map\nfor lat, lng, borough, neighborhood in zip(df_bcn['LATITUD'], df_bcn['LONGITUD'], df_bcn['Nom_Barri'], df_bcn['Nom_Districte']):\n    label = '{}, {}'.format(borough, neighborhood)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(map_bcn)  \n    \nmap_bcn\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Foursquare account\n\n1. Log in\n2. Explore venues under food category\n3. Review data - list of venues, classify per category and neigborhood\n"}, {"metadata": {}, "cell_type": "code", "source": "# @hidden_cell\n#Forusquare credentials\nCLIENT_ID = 'BCVCI0ILGJW1T2WJMVB11ZH1UM22ISIEHZ4WEXFNK3WMBHQH' # your Foursquare ID\nCLIENT_SECRET = '1WHDSKUWFXUCLRCJSNBW4TF22IGOOOCVQCOB2H12L3S3REHV' # your Foursquare Secret\nVERSION = '20191225' # Foursquare API version\n\nprint('Your credentails:')\nprint('CLIENT_ID: ' + CLIENT_ID)\nprint('CLIENT_SECRET:' + CLIENT_SECRET)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# defining radius and limit of venues to get\nradius=500\nLIMIT=100", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# limit research to restaurants (foof)\nSECTION = \"food\"", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&section={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            SECTION,\n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# type your answer here\n\nbcn_venues = getNearbyVenues(names=df_bcn['Nom_Barri'],\n                                   latitudes=df_bcn['LATITUD'],\n                                   longitudes=df_bcn['LONGITUD']\n                                  )\n\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "bcn_venues.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "bcn_venues.shape", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "bcn_venues.groupby('Neighborhood').count()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "### TRIAL Analyze each neighborhood - ONLY RESTAURANTS\n#bcn_venues.groupby('Venue Category').count()\n\n#df[df['A'].str.contains(\"hello\")]\n#bcn_rest = bcn_venues[bcn_venues['Venue Category'].str.contains(\"Restaurant\")]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\n\n#one hot encoding\nbcn_onehot = pd.get_dummies(bcn_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# add neighborhood column back to dataframe\nbcn_onehot['Neighborhood'] = bcn_venues['Neighborhood'] \n\n# move neighborhood column to the first column\nfixed_columns = [bcn_onehot.columns[-1]] + list(bcn_onehot.columns[:-1])\nbcn_onehot = bcn_onehot[fixed_columns]\n\nbcn_onehot.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "bcn_plot = bcn_venues.groupby('Venue Category').count().reset_index()\n\n#Filter those over a min\nnum = len(bcn_plot['Neighborhood'])\nsuma = bcn_plot['Neighborhood'].sum()\n\n#df.loc[df[\u2018column name\u2019] condition]\nbcn_plot_max = bcn_plot.loc[bcn_plot['Neighborhood'] >= 120]\n\n\nnum = len(bcn_plot_max['Neighborhood'])\n\n#new_row = {'Venue Category':'Rest', 'Neighborhood':suma-num, 'Neighborhood Latitude':suma-num, 'Neighborhood Longitude' :suma-num, 'Venue':suma-num,'Venue Latitude':suma-num,'Venue Longitude':suma-num}\nbcn_plot_max.loc[num]= ['Rest', suma-num, suma-num, suma-num, suma-num, suma-num, suma-num] #{'Venue Category':'Rest', 'Neighborhood':suma-num, 'Neighborhood Latitude':suma-num, 'Neighborhood Longitude' :suma-num, 'Venue':suma-num,'Venue Latitude':suma-num,'Venue Longitude':suma-num}\n#bcn_plot_max = bcn_plot_max.append(new_row, ignore_index=True)\n#bcn_plot_max\n\n\n#bcn_plot_max.plot(kind = 'pie', y='Venue', shadow = False,startangle=90, figsize=(15,10), autopct='%1.1f%%', labels=bcn_plot_max['Venue Category'], title = 'Main Restaurant types')\n\ntitle = plt.title('Main food category type', fontsize=15)\ntitle.set_ha(\"left\")\n\n#fig = plt.figure(figsize=[10, 10])\n#ax = fig.add_subplot(111)\n\nplt.gca().axis(\"equal\")\n\nlabels=bcn_plot_max['Venue Category']\nlabeldistance = 1.05\n\npie = plt.pie(bcn_plot_max['Venue'], startangle=90, autopct='%1.1f%%', radius =1.4, textprops={'fontsize': 10})\nplt.legend(pie[0],labels, bbox_to_anchor=(1,0.5), loc=\"center right\", fontsize=12, \n           bbox_transform=plt.gcf().transFigure)\n\nplt.subplots_adjust(left=0.0, bottom=0.1, right=0.45)\n\nplt.show()\nbcn_plot_max\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\n#df = pd(bcn_onehot, columns=['Neighborhood','Bakery'])\n#bcn_onehot.plot(x ='Neighborhood', y='Bakery', kind = 'bar')\n#plt.show()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "### Group rows by neighborhood and by the mean of occurrence\nbcn_grouped = bcn_onehot.groupby('Neighborhood').mean().reset_index()\nbcn_grouped\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#### Let's print each neighborhood along with the top 5 most common venues\n\nnum_top_venues = 5\n\nfor hood in bcn_grouped['Neighborhood']:\n    print(\"----\"+hood+\"----\")\n    temp = bcn_grouped[bcn_grouped['Neighborhood'] == hood].T.reset_index()\n    temp.columns = ['venue','freq']\n    temp = temp.iloc[1:]\n    temp['freq'] = temp['freq'].astype(float)\n    temp = temp.round({'freq': 2})\n    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n    print('\\n')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "### Put in pandas dataframe\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "num_top_venues = 10\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Neighborhood']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nneighborhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighborhoods_venues_sorted['Neighborhood'] = bcn_grouped['Neighborhood']\n\nfor ind in np.arange(bcn_grouped.shape[0]):\n    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(bcn_grouped.iloc[ind, :], num_top_venues)\n\nneighborhoods_venues_sorted#.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "### Cluster neighborhoods\n\n# set number of clusters\nkclusters = 5\n\nbcn_grouped_clustering = bcn_grouped.drop('Neighborhood', 1)\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(bcn_grouped_clustering)\n\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_[0:10] ", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# add clustering labels\n#Run only once\nneighborhoods_venues_sorted.insert(0, 'Cluster_Labels', kmeans.labels_) \n\nbcn_merged = df_bcn\n\n# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\nbcn_merged = bcn_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Nom_Barri')\n\nbcn_merged.tail() # check the last columns!", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\n#clean data\nbcn_merged=bcn_merged.dropna()\n#Cluster labels type\nbcn_merged['Cluster_Labels'] = bcn_merged.Cluster_Labels.astype(int)\n", "execution_count": null, "outputs": []}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "# create map\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=12)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(bcn_merged['LATITUD'], bcn_merged['LONGITUD'], bcn_merged['Nom_Barri'], bcn_merged['Cluster_Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "### Examine clusters\n\nbcn_merged.loc[bcn_merged['Cluster_Labels'] == 0, bcn_merged.columns[[1] + list(range(5, bcn_merged.shape[1]))]]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "bcn_merged.loc[bcn_merged['Cluster_Labels'] == 1, bcn_merged.columns[[1] + list(range(5, bcn_merged.shape[1]))]]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "bcn_merged.loc[bcn_merged['Cluster_Labels'] == 2, bcn_merged.columns[[1] + list(range(5, bcn_merged.shape[1]))]]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "bcn_merged.loc[bcn_merged['Cluster_Labels'] == 3, bcn_merged.columns[[1] + list(range(5, bcn_merged.shape[1]))]]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "bcn_merged.loc[bcn_merged['Cluster_Labels'] == 4, bcn_merged.columns[[1] + list(range(5, bcn_merged.shape[1]))]]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Electric car parking information\n\nLoad information related to car parking spots"}, {"metadata": {}, "cell_type": "code", "source": "### Load data about electric car parking in BCN\nbody = client_634f0334f89f49259087cb8a63af5ecf.get_object(Bucket='pythonbasics-donotdelete-pr-m6t3t6sj4zu1mf',Key='PUNTS_RECARREGA_VEHICLES_ELECTRICS.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf_data_3 = pd.read_csv(body)\ndf_data_3.head()\n\ndf_ecarpark = []\ndf_ecarpark = df_data_3[['TIPO_CONNECTOR','POTENCIA_MAXIMA_DE_CARGA_(W)', 'NUM_DE_CONNECTORS_AL_EQUIP', 'TIPOLOGIA_DE_CARREGA', 'LATITUD', 'LONGITUD']]\ndf_ecarpark = df_ecarpark.groupby(['LATITUD', 'LONGITUD'], as_index = False).agg({'TIPO_CONNECTOR': ','.join, 'POTENCIA_MAXIMA_DE_CARGA_(W)': max})\n#df.groupby(['date'], as_index = False).agg({'muscles': ','.join})\ndf_ecarpark.head(5)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Measure distance between two data points\n\ndef get_distance(lat1, lon1, lat2, lon2):\n\n    # approximate radius of earth in km\n\n    R = 6373.0\n    \n   # for lat, lon in zip(lat2, lon2)\n\n    lat1 = radians(lat1)\n    lon1 = radians(lon1)\n    lat2 = radians(lat2)\n    lon2 = radians(lon2)\n\n    dlon = lon2 - lon1\n    dlat = lat2 - lat1\n\n    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n\n    distance = R * c\n\n    return distance", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Select the reference \n#geopy.distance.vincenty(coords_1, coords_2).km\n\n# La Vila de Gracia 41.403226\t2.157236\nlat1 = df_bcn.iloc[30][3]\nlon1 = df_bcn.iloc[30][4]\n\ndf_dist = pd.DataFrame()\ndistance = []\n\n# type your answer here\n\n#for lat,lon in df_ecopark\n\n# iterate through each row and select  \n# 'Name' and 'Age' column respectively. \nfor i in range(len(df_ecarpark)) : \n    dist = get_distance(lat1, lon1, df_ecarpark.loc[i, \"LATITUD\"], df_ecarpark.loc[i, \"LONGITUD\"]) \n    distance.append(dist)\n\ndf_ecarpark['DIST'] = distance \n   \ndf_ecarpark =df_ecarpark.sort_values(by='DIST')\ndf_parking = df_ecarpark.head(10)\ndf_parking.reset_index()", "execution_count": null, "outputs": []}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "# create map\nmap_parking = folium.Map(location=[lat1, lon1], zoom_start=12)\n\n# add markers to the map\nfor lat, lon, conector, potencia_max in zip(df_parking['LATITUD'], df_parking['LONGITUD'], df_parking['TIPO_CONNECTOR'], df_parking['POTENCIA_MAXIMA_DE_CARGA_(W)']):\n    label = '{}, {} W'.format(conector, potencia_max)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=6,\n        popup=label,\n        color='green',\n        fill=True,\n        #fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(map_parking)  \n\nfolium.Marker(\n       [lat1, lon1],\n        popup='La Vila de Gracia',# 41.403226\t2.157236\n        icon=folium.Icon(color='blue', icon='map-marker')\n        ).add_to(map_parking)\n    \nmap_parking", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}